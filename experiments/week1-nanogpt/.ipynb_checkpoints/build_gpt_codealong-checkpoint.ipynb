{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build GPT from Scratch - Code Along with Karpathy\n",
    "\n",
    "**Week 1, Day 2 Activity**\n",
    "\n",
    "This notebook is for coding along with Andrej Karpathy's \"Let's build GPT: from scratch, in code, spelled out\" video.\n",
    "\n",
    "**Video Link:** https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "\n",
    "## Goal\n",
    "Build a character-level language model from scratch to deeply understand:\n",
    "- Tokenization and data preparation\n",
    "- Self-attention mechanisms\n",
    "- Multi-head attention\n",
    "- Transformer blocks\n",
    "- Full GPT architecture\n",
    "- Training and text generation\n",
    "\n",
    "## Notes\n",
    "This is exploratory/messy code. I'll extract clean implementations into `my_gpt.py` on Days 3-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shakespeare dataset\n",
    "# Implement character-level tokenization\n",
    "# Create train/val splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bigram Model\n",
    "\n",
    "Simple baseline model that predicts next character based only on current character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement bigram language model\n",
    "# Train and generate samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Attention\n",
    "\n",
    "Core mechanism that allows tokens to communicate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement self-attention mechanism\n",
    "# - Queries, Keys, Values\n",
    "# - Attention scores and masking\n",
    "# - Weighted aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Head Attention\n",
    "\n",
    "Multiple attention heads running in parallel to attend to different representation subspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement multi-head attention\n",
    "# - Multiple heads\n",
    "# - Concatenation and projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformer Blocks\n",
    "\n",
    "Complete transformer block with:\n",
    "- Multi-head attention\n",
    "- Feed-forward network\n",
    "- Layer normalization\n",
    "- Residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement transformer block\n",
    "# - Attention sublayer\n",
    "# - FFN sublayer\n",
    "# - LayerNorm and residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Full GPT Model\n",
    "\n",
    "Stack multiple transformer blocks and add token + position embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement full GPT model\n",
    "# - Token embeddings\n",
    "# - Position embeddings\n",
    "# - Stack of transformer blocks\n",
    "# - Final layer norm and linear head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# - Batch generation\n",
    "# - Forward pass and loss calculation\n",
    "# - Backward pass and optimization\n",
    "# - Logging and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generation\n",
    "\n",
    "Sample from the trained model to generate new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation\n",
    "# - Autoregressive sampling\n",
    "# - Temperature control\n",
    "# - Generate and decode samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
